"""
Imputation API routes
Handles missing value imputation with ML model support
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import List, Optional
import uuid
from datetime import datetime
from app.models.schemas import (
    ImputationMethod,
    ImputationRequest,
    ImputationResponse
)
from app.services.imputation_service import ImputationService
from app.services.ml_model_client import MLModelClient
from app.services.multiomics_imputation_service import MultiOmicsImputationService
from pathlib import Path

router = APIRouter()
imputation_service = ImputationService()
ml_client = MLModelClient()

# ë©€í‹°ì˜¤ë¯¹ìŠ¤ ì„œë¹„ìŠ¤ (ì‹±ê¸€í†¤)
multiomics_service = None

def get_multiomics_service():
    """ë©€í‹°ì˜¤ë¯¹ìŠ¤ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (lazy loading)"""
    global multiomics_service
    if multiomics_service is None:
        try:
            multiomics_service = MultiOmicsImputationService()
        except Exception as e:
            print(f"Failed to initialize MultiOmicsImputationService: {e}")
            multiomics_service = None
    return multiomics_service

# Mock imputation methods
MOCK_IMPUTATION_METHODS = [
    {
        "value": "mochi",
        "label": "ğŸš€ MOCHI: Imputation Model (ì¶”ì²œ)",
        "description": "ë©€í‹°ì˜¤ë¯¹ìŠ¤ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ìµœì‹  AI ê¸°ë°˜ ë³´ê°„ ëª¨ë¸ì…ë‹ˆë‹¤.",
        "accuracy": "~97.3%"
    },
    {
        "value": "mean",
        "label": "Mean/Median Imputation",
        "description": "ê°€ì¥ ê°„ë‹¨í•œ í†µê³„ì  ë°©ë²•ìœ¼ë¡œ, ê° ë³€ìˆ˜ì˜ í‰ê·  ë˜ëŠ” ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.",
        "accuracy": "~75%"
    },
    {
        "value": "knn",
        "label": "KNN (K-Nearest Neighbors) Imputation",
        "description": "ìœ ì‚¬í•œ ìƒ˜í”Œë“¤ì˜ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.",
        "accuracy": "~88%"
    },
    # TODO: MICEëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°(íŠ¹ì„± ìˆ˜ > 10,000)ì— ëŒ€í•´ ê³„ì‚° ì‹œê°„ì´ ë§¤ìš° ì˜¤ë˜ ê±¸ë¦¼ (ìˆ˜ ì‹œê°„)
    # ì¶”í›„ ìƒ˜í”Œë§ ë˜ëŠ” PCA ê¸°ë°˜ ì°¨ì› ì¶•ì†Œ ë“±ì˜ ìµœì í™” í•„ìš”
    # {
    #     "value": "mice",
    #     "label": "MICE (Multiple Imputation by Chained Equations)",
    #     "description": "ë‹¤ì¤‘ ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ì™„ì „í•œ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.",
    #     "accuracy": "~92%"
    # },
    {
        "value": "missforest",
        "label": "MissForest",
        "description": "Random Forest ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ ë¹„ëª¨ìˆ˜ì  ë³´ê°„ ë°©ë²•ì…ë‹ˆë‹¤.",
        "accuracy": "~91%"
    },
    {
        "value": "gain",
        "label": "GAIN (Generative Adversarial Imputation)",
        "description": "GAN ê¸°ë°˜ì˜ ìƒì„± ëª¨ë¸ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ë³´ê°„í•©ë‹ˆë‹¤.",
        "accuracy": "~94%"
    },
    {
        "value": "vae",
        "label": "VAE (Variational Autoencoder)",
        "description": "ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ìƒì„± ëª¨ë¸ë¡œ, ë°ì´í„°ì˜ ì ì¬ í‘œí˜„ì„ í•™ìŠµí•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.",
        "accuracy": "~93%"
    },
]


imputation_jobs = {}


@router.get("/methods", response_model=List[ImputationMethod])
async def get_imputation_methods():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë³´ê°„ ë°©ë²• ëª©ë¡ ì¡°íšŒ"""
    return MOCK_IMPUTATION_METHODS


@router.post("/execute", response_model=ImputationResponse)
async def execute_imputation(
    request: ImputationRequest,
    background_tasks: BackgroundTasks
):
    """ê²°ì¸¡ì¹˜ ë³´ê°„ ì‹¤í–‰"""
    job_id = str(uuid.uuid4())
    
    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ë³´ê°„ ì‹¤í–‰
    background_tasks.add_task(
        imputation_service.run_imputation,
        job_id=job_id,
        project_id=request.project_id,
        method=request.method,
        threshold=request.threshold,
        quality_threshold=request.quality_threshold,
        options=request.options or {}
    )
    
    imputation_jobs[job_id] = {
        "status": "processing",
        "created_at": datetime.now().isoformat(),
        "request": request.model_dump()
    }
    
    return ImputationResponse(
        jobId=job_id,
        status="processing",
        message="Imputation job started",
        estimatedTime=300  # 5ë¶„ ì˜ˆìƒ
    )


@router.get("/status/{job_id}")
async def get_imputation_status(job_id: str):
    """ë³´ê°„ ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    # imputation_serviceì˜ jobs ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒíƒœ í™•ì¸
    job = imputation_service.jobs.get(job_id)
    if job:
        # ì„œë¹„ìŠ¤ì—ì„œ ì™„ë£Œ/ì‹¤íŒ¨ ìƒíƒœê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë©´ ë¡œì»¬ ë”•ì…”ë„ˆë¦¬ë„ ì—…ë°ì´íŠ¸
        imputation_jobs[job_id] = job
        return job

    # ì„œë¹„ìŠ¤ì— ì—†ìœ¼ë©´ ë¡œì»¬ ë”•ì…”ë„ˆë¦¬ì—ì„œ í™•ì¸ (ì´ˆê¸° processing ìƒíƒœ)
    job = imputation_jobs.get(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    return job


@router.get("/results/{job_id}")
async def get_imputation_results(job_id: str):
    """ë³´ê°„ ê²°ê³¼ ì¡°íšŒ"""
    # imputation_serviceì˜ jobs ë”•ì…”ë„ˆë¦¬ì—ì„œ í™•ì¸
    job = imputation_service.jobs.get(job_id)
    if not job:
        job = imputation_jobs.get(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")

    if job["status"] != "completed":
        raise HTTPException(status_code=400, detail="Job not completed yet")

    # ì‹¤ì œ ê²°ê³¼ ë°ì´í„° ë°˜í™˜
    return {
        "job_id": job_id,
        "status": "completed",
        "method": job.get("method"),
        "results": job.get("results", {})
    }


@router.get("/ml-model/connection-test")
async def test_ml_model_connection():
    """ML ëª¨ë¸ ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        is_connected = ml_client.check_connection()
        if is_connected:
            return {
                "status": "success",
                "message": "Successfully connected to ML model server",
                "connected": True
            }
        else:
            return {
                "status": "failed",
                "message": "Failed to connect to ML model server",
                "connected": False
            }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Connection test failed: {str(e)}"
        )


@router.get("/ml-model/list")
async def list_ml_models():
    """ì›ê²© ì„œë²„ì˜ ML ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        models = ml_client.list_models()
        return {
            "status": "success",
            "models": models,
            "count": len(models)
        }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to list models: {str(e)}"
        )



@router.post("/execute-multiomics")
async def execute_multiomics_imputation(
    project_id: int,
    threshold: float = 30.0,
    quality_threshold: float = 85.0,
    background_tasks: BackgroundTasks = None
):
    """
    ë©€í‹°ì˜¤ë¯¹ìŠ¤ ë°ì´í„° ë³´ê°„ ì‹¤í–‰ (RNA, Protein, Methyl)

    í”„ë¡œì íŠ¸ì— ì—…ë¡œë“œëœ 3ì¢…ë¥˜ì˜ omics ë°ì´í„°ì— ëŒ€í•´
    MOCHI tri-joint ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²°ì¸¡ì¹˜ ë³´ê°„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Parameters:
    - project_id: í”„ë¡œì íŠ¸ ID
    - threshold: ë³´ê°„ ì„ê³„ê°’ (%) - ì´ ë¹„ìœ¨ ì´í•˜ì˜ ê²°ì¸¡ë§Œ ë³´ê°„
    - quality_threshold: í’ˆì§ˆ ê¸°ì¤€ (%) - ë³´ê°„ í›„ ìµœì†Œ í’ˆì§ˆ ì ìˆ˜
    """
    job_id = str(uuid.uuid4())

    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ë³´ê°„ ì‹¤í–‰
    background_tasks.add_task(
        _run_multiomics_imputation,
        job_id=job_id,
        project_id=project_id,
        threshold=threshold,
        quality_threshold=quality_threshold
    )

    imputation_jobs[job_id] = {
        "status": "processing",
        "created_at": datetime.now().isoformat(),
        "project_id": project_id,
        "method": "mochi_multiomics",
        "threshold": threshold,
        "quality_threshold": quality_threshold
    }

    return {
        "jobId": job_id,
        "status": "processing",
        "message": "Multi-omics imputation job started",
        "estimatedTime": 180
    }


def _run_multiomics_imputation(job_id: str, project_id: int, threshold: float = 30.0, quality_threshold: float = 85.0):
    """ë©€í‹°ì˜¤ë¯¹ìŠ¤ ë³´ê°„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…"""
    try:
        print(f"[Job {job_id}] Starting multi-omics imputation for project {project_id}")
        print(f"[Job {job_id}] Parameters - threshold: {threshold}%, quality_threshold: {quality_threshold}%")

        # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        service = get_multiomics_service()
        if service is None:
            raise RuntimeError("Failed to initialize MultiOmicsImputationService")

        # ë°ì´í„° ë¡œë“œ
        data_dir = Path("/home/humandeep/data-qc/uploads")
        rna_df, protein_df, methyl_df = service.load_multiomics_data(project_id, data_dir)

        if rna_df is None or protein_df is None or methyl_df is None:
            missing = []
            if rna_df is None:
                missing.append("RNA")
            if protein_df is None:
                missing.append("Protein")
            if methyl_df is None:
                missing.append("Methyl")
            raise ValueError(f"Missing required omics data: {', '.join(missing)}")

        print(f"[Job {job_id}] Data loaded - RNA: {rna_df.shape}, Protein: {protein_df.shape}, Methyl: {methyl_df.shape}")

        # ë³´ê°„ ìˆ˜í–‰
        results = service.impute_multiomics(rna_df, protein_df, methyl_df)

        # ë³´ê°„ ê²°ê³¼ ì €ì¥
        output_dir = data_dir / f"project_{project_id}" / "imputed"
        output_dir.mkdir(parents=True, exist_ok=True)

        rna_output = output_dir / f"{job_id}_rna_imputed.tsv"
        protein_output = output_dir / f"{job_id}_protein_imputed.tsv"
        methyl_output = output_dir / f"{job_id}_methyl_imputed.tsv"

        results['rna'].to_csv(rna_output, sep="\t")
        results['protein'].to_csv(protein_output, sep="\t")
        results['methyl'].to_csv(methyl_output, sep="\t")

        print(f"[Job {job_id}] Results saved to {output_dir}")

        # ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸
        stats = results['statistics']
        imputation_jobs[job_id] = {
            "status": "completed",
            "created_at": imputation_jobs[job_id]["created_at"],
            "completed_at": datetime.now().isoformat(),
            "project_id": project_id,
            "method": "mochi_multiomics",
            "results": {
                "rna_missing_imputed": int(stats['rna_missing_before']),
                "protein_missing_imputed": int(stats['protein_missing_before']),
                "methyl_missing_imputed": int(stats['methyl_missing_before']),
                "total_samples": int(stats['total_samples']),
                "output_files": {
                    "rna": str(rna_output),
                    "protein": str(protein_output),
                    "methyl": str(methyl_output)
                }
            }
        }

        print(f"[Job {job_id}] Multi-omics imputation completed successfully")

    except Exception as e:
        print(f"[Job {job_id}] Multi-omics imputation failed: {str(e)}")
        import traceback
        traceback.print_exc()

        imputation_jobs[job_id] = {
            "status": "failed",
            "created_at": imputation_jobs[job_id]["created_at"],
            "failed_at": datetime.now().isoformat(),
            "project_id": project_id,
            "error": str(e)
        }


@router.get("/download/{job_id}/{omics_type}")
async def download_imputed_data(job_id: str, omics_type: str):
    """
    ë³´ê°„ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ

    Parameters:
    - job_id: ë³´ê°„ ì‘ì—… ID
    - omics_type: ì˜¤ë¯¹ìŠ¤ íƒ€ì… (rna, protein, methyl)
    """
    from fastapi.responses import FileResponse

    job = imputation_jobs.get(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    if job["status"] != "completed":
        raise HTTPException(status_code=400, detail="Job not completed yet")

    # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    output_files = job.get("results", {}).get("output_files", {})
    file_path = output_files.get(omics_type)

    if not file_path or not Path(file_path).exists():
        raise HTTPException(status_code=404, detail=f"{omics_type} imputed data file not found")

    # íŒŒì¼ëª… ìƒì„±
    filename = f"{omics_type}_imputed_{job_id}.tsv"

    return FileResponse(
        path=file_path,
        filename=filename,
        media_type="text/tab-separated-values"
    )
